{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7g7bxFCHxGP"
   },
   "source": [
    "$${\\color{yellow}{\\text{Applied Linear Algebra---Vectors and Matrices}}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_BbyTKXQflD"
   },
   "source": [
    "---\n",
    "\n",
    "Load essential libraries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 18594,
     "status": "ok",
     "timestamp": 1754023517291,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "KVtefj_HKd59",
    "outputId": "7e6cd2c8-9440-485a-c8c0-0fddcac2f26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.17.3-cp39-cp39-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Downloading gensim-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m390.4 kB/s\u001b[0m  \u001b[33m0:01:09\u001b[0mm0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m570.8 kB/s\u001b[0m  \u001b[33m0:00:32\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hUsing cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "Downloading smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
      "Downloading wrapt-1.17.3-cp39-cp39-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (81 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [gensim]2m4/5\u001b[0m [gensim]pen]\n",
      "\u001b[1A\u001b[2KSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.3.1 wrapt-1.17.3\n"
     ]
    }
   ],
   "source": [
    "!pip install  gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDK9fC6uiBGE"
   },
   "source": [
    "---\n",
    "\n",
    "After reinstalling numpy and gensim, go to *Runtime -> Restart Session* and execute from the following cell onward:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9291,
     "status": "ok",
     "timestamp": 1754023537216,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "20W0d4ruQjE4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdark_background\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "import nltk\n",
    "import gensim.downloader\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfYXkqmLiVLM"
   },
   "source": [
    "---\n",
    "\n",
    "Mount Google Drive folder if running Google Colab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYzBBBxqiaGa"
   },
   "outputs": [],
   "source": [
    "## Mount Google drive folder if running in Colab\n",
    "if('google.colab' in sys.modules):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount = True)\n",
    "    DIR = '/content/drive/MyDrive/Colab Notebooks/ALA'\n",
    "    DATA_DIR = DIR+'/Data/'\n",
    "else:\n",
    "    DATA_DIR = '../Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avVZ6D1ZgEUT"
   },
   "source": [
    "---\n",
    "\n",
    "**We will now use Pytorch to create tensors**\n",
    "\n",
    "The patient data matrix:\n",
    "\n",
    "![patient data matrix](https://1drv.ms/i/s!AjTcbXuSD3I3hsxIkL4V93-CGq8RkQ?embed=1&width=1000)\n",
    "\n",
    "**Notation**:\n",
    "\n",
    "Zeroth patient vector $\\mathbf{x}^{(0)}= \\begin{bmatrix}72\\\\120\\\\37.3\\\\104\\\\32.5\\end{bmatrix}$ and zeroth feature (heart rate vector) $\\mathbf{x}_0 = \\begin{bmatrix}72\\\\85\\\\68\\\\90\\\\84\\\\78\\end{bmatrix}.$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1753771041623,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "zrPnepAEvr0O",
    "outputId": "7e9ef153-c20b-4ce7-cad2-ababf94b7fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000],\n",
      "        [ 85.0000, 130.0000,  37.0000, 110.0000,  14.0000],\n",
      "        [ 68.0000, 110.0000,  38.5000, 125.0000,  34.0000],\n",
      "        [ 90.0000, 140.0000,  38.0000, 130.0000,  26.0000],\n",
      "        [ 84.0000, 132.0000,  38.3000, 146.0000,  30.0000],\n",
      "        [ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000]])\n"
     ]
    }
   ],
   "source": [
    "## Create a patient data matrix as a constant tensor\n",
    "X = torch.tensor([[72,120,37.3,104,32.5],\n",
    "                  [85,130,37.0,110,14],\n",
    "                  [68,110,38.5,125,34],\n",
    "                  [90,140,38.0,130,26],\n",
    "                  [84,132,38.3,146,30],\n",
    "                  [78,128,37.2,102,12]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1753771966561,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "012dGSGZ6tFX",
    "outputId": "ede279f5-87ec-4a94-ef7b-d8405eebc1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000])\n",
      "tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000])\n",
      "---------------\n",
      "tensor(37.3000)\n",
      "tensor([37.3000, 37.0000, 38.5000, 38.0000, 38.3000, 37.2000])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(type(X))\n",
    "print(X[0]) #rank1 tensor, vector, row\n",
    "print(X[0,:])\n",
    "print(\"---------------\")\n",
    "print(X[0,2]) #feature 2 of paitnt zero\n",
    "print(X[:,2]) # \":\" = for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cevtn_b4gek5"
   },
   "source": [
    "---\n",
    "\n",
    "**Convert a PyTorch object into a numpy array**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1753772271020,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "JrYQ2moygfPu",
    "outputId": "ad715753-5e57-4fb1-f32d-97b2bce605ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 72.  120.   37.3 104.   32.5]\n",
      " [ 85.  130.   37.  110.   14. ]\n",
      " [ 68.  110.   38.5 125.   34. ]\n",
      " [ 90.  140.   38.  130.   26. ]\n",
      " [ 84.  132.   38.3 146.   30. ]\n",
      " [ 78.  128.   37.2 102.   12. ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X.numpy())\n",
    "print(type(X.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QS3MmzwsgkWU"
   },
   "source": [
    "---\n",
    "\n",
    "**Addition and subtraction of vectors, scalar multiplication (apply operation componentwise)**\n",
    "\n",
    "![vector addition](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3NokBAAAAAZLAaAoWwhtn8Vk26NotALo?width=256)\n",
    "\n",
    "![vector subtracton](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3M4kBAAAAAU_n_mAEv006QFZm_sUj2Dc?width=256)\n",
    "\n",
    "![vector multiplication](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3NIkBAAAAAa_qL04bLT4kWoNeHcrR9LQ?width=256)\n",
    "\n",
    "![vector geometry1](https://1drv.ms/i/c/37720f927b6ddc34/IQSGNMr5z3SSRry7LSKL7LybAcGYuzgw5smabV8-6DudXIs?width=230)\n",
    "\n",
    "![vector geometry2](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3WokBAAAAAQi8FPV9YCebl5WnyEKJ3vg?width=213&height=192)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1753774440845,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "TgPtJP0sglQP",
    "outputId": "9cd27806-4ebf-4fa6-dd67-378f22508f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([153.0000, 240.0000,  75.5000, 235.0000,  48.0000])\n",
      "tensor([ 17.0000,  20.0000,  -1.5000, -15.0000, -20.0000])\n",
      "tensor([37.3000, 37.0000, 38.5000, 38.0000, 38.3000, 37.2000])\n",
      "tensor([ 99.1400,  98.6000, 101.3000, 100.4000, 100.9400,  98.9600])\n",
      "tensor([ 79.5000, 126.6667,  37.7167, 119.5000,  24.7500])\n",
      "tensor([[ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000],\n",
      "        [ 85.0000, 130.0000,  37.0000, 110.0000,  14.0000],\n",
      "        [ 68.0000, 110.0000,  38.5000, 125.0000,  34.0000],\n",
      "        [ 90.0000, 140.0000,  38.0000, 130.0000,  26.0000],\n",
      "        [ 84.0000, 132.0000,  38.3000, 146.0000,  30.0000],\n",
      "        [ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000]])\n",
      "tensor([ 79.5000, 126.6667,  37.7167, 119.5000,  24.7500])\n",
      "tensor([[ -7.5000,  -6.6667,  -0.4167, -15.5000,   7.7500],\n",
      "        [  5.5000,   3.3333,  -0.7167,  -9.5000, -10.7500],\n",
      "        [-11.5000, -16.6667,   0.7833,   5.5000,   9.2500],\n",
      "        [ 10.5000,  13.3333,   0.2833,  10.5000,   1.2500],\n",
      "        [  4.5000,   5.3333,   0.5833,  26.5000,   5.2500],\n",
      "        [ -1.5000,   1.3333,  -0.5167, -17.5000, -12.7500]])\n"
     ]
    }
   ],
   "source": [
    "# Vector addition\n",
    "print(X[1,:]+ X[2,:])\n",
    "\n",
    "# Vector subtraction\n",
    "print(X[1,:]- X[2,:])\n",
    "\n",
    "# Scalar-vector multiplication (the temperature of all patients)\n",
    "print(X[:,2])\n",
    "\n",
    "\n",
    "# Operation not defined in pen & paper but in computation is referred to as\n",
    "# broadcasting\n",
    "print(9/5*X[:,2] + 32)\n",
    "\n",
    "# Average patient\n",
    "X_avg=(1/6)*(X[0,:] + X[1,:] + X[2,:] + X[3,:] + X[4,:] + X[5,:])\n",
    "X_avg =torch.mean(X, dim = 0)\n",
    "print(X_avg)\n",
    "\n",
    "# Another BC example\n",
    "print(X)\n",
    "print(X_avg)\n",
    "print(X - X_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1t_qXrlCROKA"
   },
   "source": [
    "---\n",
    "\n",
    "Application of vector subtraction in natural language processing (NLP): download the word embedding model trained on Wikipedia articles.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27653,
     "status": "ok",
     "timestamp": 1753852862569,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "_e13FnW0RUwy",
    "outputId": "fcf2c8e0-eef0-4804-dbbf-c028f09346f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YRVJferRlK5"
   },
   "source": [
    "---\n",
    "\n",
    "Now we will see what embedding vector comes as a result of applying the model for the words *cricket* and *football*.\n",
    "\n",
    "Next, we will do an *intuitive* subtraction of word embeddings as in\n",
    "\n",
    "1. Cricket without Tendulkar\n",
    "2. Football without Messi\n",
    "\n",
    "Note that the embedding vectors have 50 components corresponding to the 50-dimensional embedding of model suggested by the name '**glove-wiki-gigaword-50**'\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1753854208257,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "HVVFzeQyR3Wb",
    "outputId": "7168745d-3d27-44ac-d333-2a38a7006a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7716      0.41267997 -1.725968   -0.10445005 -1.1475699  -0.854661\n",
      " -1.089      -0.08342999  0.62349    -1.67822    -0.2488078  -0.49199998\n",
      "  0.18756002 -1.67098     0.6117872   0.42784432  1.05656     0.91583097\n",
      " -0.03299999 -0.04422501  0.200326   -0.33737004  0.31068     1.37842\n",
      " -1.13689    -0.57445    -0.70685995  0.41552    -0.28937     0.54485\n",
      "  1.0492998   0.62732    -0.8105     -1.27723    -0.02612001  0.53963\n",
      " -0.14065999 -0.738244   -0.30487    -1.18129     0.05651999 -0.993618\n",
      " -0.911399   -0.09289992  0.535432    0.26259995 -0.63031     0.64473\n",
      "  0.77843     0.15099996]\n",
      "[-2.39615     1.28039    -0.03170002 -0.01047    -0.20375    -1.69358\n",
      " -1.7819899  -0.24751002 -0.29028    -0.66169     2.12637     0.47897002\n",
      " -0.22283    -1.27695     0.03970003 -0.101797    0.701239    1.0410299\n",
      " -2.7329001   0.91248    -1.1445099  -0.61319     0.38945     0.82259\n",
      " -1.15223    -1.64179     0.47020102 -0.72381    -2.34939    -1.1116099\n",
      "  1.62972     1.2446101  -0.02259    -0.56705     0.76486     0.19003004\n",
      "  0.8412     -0.15134999 -0.5301     -0.28561002  0.71554    -0.198248\n",
      " -0.50832    -0.78837    -0.31803003  0.827822   -0.68492997  1.23263\n",
      " -0.47383898 -0.88515997]\n",
      "[ 1.6245501  -0.86771005 -1.694268   -0.09398004 -0.9438199   0.83891904\n",
      "  0.69298995  0.16408002  0.91376996 -1.01653    -2.3751779  -0.97097003\n",
      "  0.41039002 -0.39402997  0.57208717  0.52964133  0.35532105 -0.12519896\n",
      "  2.6999002  -0.956705    1.3448359   0.27581996 -0.07877001  0.55583\n",
      "  0.01533997  1.06734    -1.177061    1.13933     2.06002     1.6564599\n",
      " -0.58042014 -0.6172901  -0.78791004 -0.71018004 -0.79098     0.34959996\n",
      " -0.98186    -0.58689404  0.22522998 -0.89568    -0.65902    -0.79537\n",
      " -0.40307903  0.6954701   0.853462   -0.5652221   0.05461997 -0.58790004\n",
      "  1.252269    1.03616   ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#cricket without tandulkar\n",
    "a=model['cricket'] - model['tendulkar']\n",
    "print(a)\n",
    "#football without messy\n",
    "b=model['football'] - model['messy']\n",
    "print(b)\n",
    "#diffrence\n",
    "print(a-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VPICS8ggvvg"
   },
   "source": [
    "---\n",
    "\n",
    "A tensor of rank 3 corresponding to 4 time stamps (hourly), 3 samples (patients), 2 features (HR and BP). Assume that admission time is 9AM.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1753855153385,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "yQAvgkRkWAM8",
    "outputId": "e32ad84a-7a4f-4d0c-a284-bad1f981eecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 74., 128.],\n",
      "         [ 79., 116.],\n",
      "         [ 71., 116.]],\n",
      "\n",
      "        [[ 78., 118.],\n",
      "         [ 82., 124.],\n",
      "         [ 72., 128.]],\n",
      "\n",
      "        [[ 84., 138.],\n",
      "         [ 84., 130.],\n",
      "         [ 74., 120.]],\n",
      "\n",
      "        [[ 82., 126.],\n",
      "         [ 76., 156.],\n",
      "         [ 82., 132.]]])\n"
     ]
    }
   ],
   "source": [
    "# A rank-3 patient tensor with shape (4, 3, 2)\n",
    "# with meaning for\n",
    "# dim-0 as 4 hourly timestamps,\n",
    "# dim-1 as 3 patients, and\n",
    "# dim-2 as 2 features (HR and BP)\n",
    "# T- torch- tendor()\n",
    "T = torch.tensor([[[74., 128], [79, 116], [71, 116]],\n",
    "                 [[78, 118], [82, 124], [72, 128]],\n",
    "                 [[84, 138], [84, 130], [74, 120]],\n",
    "                 [[82, 126], [76, 156], [82, 132]]])\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV0fpSojg2EZ"
   },
   "source": [
    "---\n",
    "\n",
    "**Accessing elements of a tensor**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1753857023184,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "1GbZuDYqg22n",
    "outputId": "a0b228ba-96b8-4809-85c2-634afd1a38c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 74., 120.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Accessing elements of a tensor\n",
    "# Rank-3 tensor T has axes order (timestamps, patients, features)\n",
    "\n",
    "# Element of T at postion 3 w.r.t. axis-0, position 2 w.r.t. axis-1,\n",
    "# position-1 w.r.t axis-2\n",
    "T[3,2,1]\n",
    "\n",
    "# Element-0 of object T which is also the info for all patients at\n",
    "# admission time 9AM\n",
    "T[0]\n",
    "\n",
    "# Patient-2 info at 12PM\n",
    "T[2,2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW2_NDTCjIL5"
   },
   "source": [
    "---\n",
    "\n",
    "**Broadcasting**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PjnkDnr_qSn"
   },
   "outputs": [],
   "source": [
    "# A simple broadcasting example\n",
    "a = torch.tensor([[1.0, 2.0, 3.0]])\n",
    "b = torch.tensor([4.0])\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhtxw34i_RNt"
   },
   "outputs": [],
   "source": [
    "# How to add a new axis to a tensor using the unsqueeze() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEPPWVsWjI4X"
   },
   "outputs": [],
   "source": [
    "# How different are the patients from patient-0?\n",
    "#T - T[:, 0, :] # does not work for broadcasting\n",
    "\n",
    "\n",
    "#  # How different are the patients compared to their time at admission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o6kEXfCpDzo"
   },
   "source": [
    "---\n",
    "\n",
    "**Exercise**: interpret $\\texttt{T[:, -1, :]}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6lEPZEWo6wo"
   },
   "outputs": [],
   "source": [
    "# Last patient's info at all timestamps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gc9EJuZQhD9i"
   },
   "source": [
    "---\n",
    "\n",
    "$l_2$ norm or the geometric length of a vector denoted as $\\lVert \\mathbf{a}\\rVert$ tells us how long a vector is. In 2-dimensions, $$\\lVert \\mathbf{a}\\rVert_2 = \\sqrt{a_1^2+a_2^2}$$ and in $n$-dimensions, $$\\lVert \\mathbf{a}\\rVert_2 = \\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}.$$\n",
    "\n",
    "![vector norm](https://1drv.ms/i/c/37720f927b6ddc34/IQT817WmpQjlRqZ1R0d5Cfv6AUW6c4robL-gk06i9wmCaFU?width=500)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OM65UP4_hEso"
   },
   "outputs": [],
   "source": [
    "## l2 norm of a vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRbanrUmwLX7"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Dot Product of Vectors**\n",
    "\n",
    "A scalar resulting from an elementwise multiplication and addition: $$\\mathbf{a}{\\color{cyan}\\cdot}\\mathbf{b} = {\\color{red}{a_1b_1}}+{\\color{green}{a_2b_2}}+\\cdots+{\\color{magenta}{a_nb_n}}$$\n",
    "\n",
    "The <font color=\"cyan\">dot</font> ${\\color{cyan}\\cdot}$ represents the computation of the dot product.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s91XY1JZwU2w"
   },
   "outputs": [],
   "source": [
    "## Dot product of vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-b90m-QXyFp"
   },
   "source": [
    "---\n",
    "\n",
    "The dot product is a measure of similarity between vectors (or, how aligned they are geometrically).\n",
    "\n",
    "![dot product](https://1drv.ms/i/c/37720f927b6ddc34/IQTbcGSjdbhSTJ7J39d5BCWAAWS6-y5U6J87vHuDWeAqGwM?width=6000)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GxZ95uXXz3P"
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([1.0, 2.0])\n",
    "b = torch.tensor([2.0, 4.0])\n",
    "c = torch.tensor([-2.0, 1.0])\n",
    "d = torch.tensor([-1.0, -2.0])\n",
    "print(torch.dot(a, b))\n",
    "print(torch.dot(a, c))\n",
    "print(torch.dot(a, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6CS4_8byCs8"
   },
   "source": [
    "---\n",
    "\n",
    "Cauchy-Schwarz inequality $-1\\leq\\frac{\\mathbf{x}\\cdot{\\mathbf{y}}}{\\lVert\\mathbf{x}\\rVert_2\\lVert\\mathbf{y}\\rVert_2}\\leq1.$\n",
    "\n",
    "This is a normalized measure of similarity (or extent of alignment) between vectors.\n",
    "\n",
    "Angle between vectors $\\mathbf{x}$ and $\\mathbf{y} = \\cos^{-1}\\left(\\frac{\\mathbf{x}\\cdot{\\mathbf{y}}}{\\lVert\\mathbf{x}\\rVert_2\\lVert\\mathbf{y}\\rVert_2}\\right).$\n",
    "\n",
    "![angle](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3WokBAAAAAQi8FPV9YCebl5WnyEKJ3vg?width=213&height=400)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "error",
     "timestamp": 1754023687887,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "q4UhBnPUx7TV",
    "outputId": "5c218f17-afb3-4491-8937-3eb002dc2c52"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4087316715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Angle between x and y in radians\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Angle between x and y in degrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0])\n",
    "y = torch.tensor([2.0, 1.0])\n",
    "d=prtorch.dot(a, b))\n",
    "# Angle between x and y in radians\n",
    "import math\n",
    "r = math.acos(d)\n",
    "print(r)\n",
    "# Angle between x and y in degrees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bnmEkg3Tctx"
   },
   "source": [
    "---\n",
    "\n",
    "Application of the Cauchy-Schwarz inequality: is \"Cricket without Tendulkar\" same as \"Football without Messi\"?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrmCknO5TkNZ"
   },
   "outputs": [],
   "source": [
    "a = model['cricket'] - model['tendulkar']\n",
    "b = model['football'] - model['messi']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayzM_0_synRF"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Hadamard Product of Vectors**\n",
    "\n",
    "A vector resulting from an elementwise multiplication: $$\\mathbf{a}{\\color{cyan}\\otimes}\\mathbf{b} = \\begin{bmatrix}{\\color{red}{a_1\\times b_1}}\\\\{\\color{green}{a_2\\times b_2}}\\\\\\vdots\\\\{\\color{magenta}{a_n\\times b_n}}\\end{bmatrix}.$$\n",
    "\n",
    "The <font color=\"cyan\">$\\otimes$</font> represents the computation of the Hadamard product.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPojS0rIzR8p"
   },
   "outputs": [],
   "source": [
    "## Hadamard product\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "# Element-wise multiplication (Hadamard product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oruyV_EjhqCR"
   },
   "source": [
    "---\n",
    "\n",
    "A matrix-vector product is simply a sequence of dot products of the rows of the matrix (seen as vectors) with the vector\n",
    "\n",
    "![matvec product](https://1drv.ms/i/c/37720f927b6ddc34/IQQ1cQ8fZdFmS4cnGkBlsZbAAaL2zMtzWdjHe-HCMt4UTA0?width=700)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_IScSWzhpi7"
   },
   "outputs": [],
   "source": [
    "## Matrix-vector product\n",
    "A = torch.tensor([[1.0, 2.0, 4.0],\n",
    "                  [2.0, -1.0, 3.0]])\n",
    "x = torch.tensor([4.0, 2.0, -2.0])\n",
    "\n",
    "# Matrix-vector multiplication\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTnGSJ3vT4EN"
   },
   "source": [
    "---\n",
    "\n",
    "Here we create a simple sentence in English and tokenize it\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQ73kkevT5L3"
   },
   "outputs": [],
   "source": [
    "sentence = 'i swam quickly across the river to get to the other bank'\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M40pqI8UUbX4"
   },
   "source": [
    "---\n",
    "\n",
    "Generate the word embeddings for the tokens and store them in a matrix $\\mathbf{X}$ such that each row of the matrix corresponds to a token.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mKKVRyxUh5V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z0pZQisxtY-"
   },
   "source": [
    "---\n",
    "\n",
    "A matrix-matrix product is simply a sequence of matrix-vector products.\n",
    "\n",
    "![matmatprod](https://1drv.ms/i/c/37720f927b6ddc34/IQQ-B3z7tbWHQqBrW9k2ElDVAUc5fWzM24txLkgBK7f8Yac?width=550)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSg1brJ9yKnM"
   },
   "outputs": [],
   "source": [
    "## Matrix-matrix product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVoJRc6kUtI2"
   },
   "source": [
    "---\n",
    "\n",
    "The similarity between each pair of words represented in the word embeddings matrix $\\mathbf{X}_\\mathrm{word}$ is the matrix-matrix product $\\mathbf{X}_\\mathrm{word}\\mathbf{X}_\\mathrm{word}^\\mathrm{T}.$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ms9Qg5AoVJy_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ALA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
