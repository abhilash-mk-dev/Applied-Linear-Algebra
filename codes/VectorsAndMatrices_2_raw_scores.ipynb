{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7g7bxFCHxGP"
   },
   "source": [
    "$${\\color{yellow}{\\text{Applied Linear Algebra: Vectors and Matrices}}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6RvcDldxHPO"
   },
   "source": [
    "---\n",
    "\n",
    "Restart the session after executing the following cell\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "executionInfo": {
     "elapsed": 34419,
     "status": "ok",
     "timestamp": 1754372307360,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "LapV0XR-wxSI",
    "outputId": "2305aa11-0e3f-4155-e2be-63700b1ac124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.16.0\n",
      "    Uninstalling scipy-1.16.0:\n",
      "      Successfully uninstalled scipy-1.16.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "6cb0f98c0dcf408fb736c8dcb766ef2a",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDK9fC6uiBGE"
   },
   "source": [
    "---\n",
    "\n",
    "Load essential libraries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 16674,
     "status": "ok",
     "timestamp": 1754372332962,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "20W0d4ruQjE4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "import nltk\n",
    "import gensim.downloader\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfYXkqmLiVLM"
   },
   "source": [
    "---\n",
    "\n",
    "Mount Google Drive folder if running Google Colab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYzBBBxqiaGa"
   },
   "outputs": [],
   "source": [
    "## Mount Google drive folder if running in Colab\n",
    "if('google.colab' in sys.modules):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount = True)\n",
    "    DIR = '/content/drive/MyDrive/Colab Notebooks/ALA'\n",
    "    DATA_DIR = DIR+'/Data/'\n",
    "else:\n",
    "    DATA_DIR = '../Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avVZ6D1ZgEUT"
   },
   "source": [
    "---\n",
    "\n",
    "**We will now use Pytorch to create tensors**\n",
    "\n",
    "The patient data matrix:\n",
    "\n",
    "![patient data matrix](https://1drv.ms/i/s!AjTcbXuSD3I3hsxIkL4V93-CGq8RkQ?embed=1&width=1000)\n",
    "\n",
    "**Notation**:\n",
    "\n",
    "Zeroth patient vector $\\mathbf{x}^{(0)}= \\begin{bmatrix}72\\\\120\\\\37.3\\\\104\\\\32.5\\end{bmatrix}$ and zeroth feature (heart rate vector) $\\mathbf{x}_0 = \\begin{bmatrix}72\\\\85\\\\68\\\\90\\\\84\\\\78\\end{bmatrix}.$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1753854470956,
     "user": {
      "displayName": "S N S Acharya",
      "userId": "14786945180387920086"
     },
     "user_tz": -330
    },
    "id": "zrPnepAEvr0O",
    "outputId": "e8211816-bfbb-43bd-cc2c-1cff75f3e340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000],\n",
      "        [ 85.0000, 130.0000,  37.0000, 110.0000,  14.0000],\n",
      "        [ 68.0000, 110.0000,  38.5000, 125.0000,  34.0000],\n",
      "        [ 90.0000, 140.0000,  38.0000, 130.0000,  26.0000],\n",
      "        [ 84.0000, 132.0000,  38.3000, 146.0000,  30.0000],\n",
      "        [ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000]])\n",
      "torch.Size([6, 5])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000])\n",
      "tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000])\n",
      "------------\n",
      "tensor(37.3000)\n",
      "tensor([37.3000, 37.0000, 38.5000, 38.0000, 38.3000, 37.2000])\n"
     ]
    }
   ],
   "source": [
    "## Create a patient data matrix as a constant tensor\n",
    "X = torch.tensor([[72, 120, 37.3, 104, 32.5],\n",
    "                  [85, 130, 37.0, 110, 14],\n",
    "                  [68, 110, 38.5, 125, 34],\n",
    "                  [90, 140, 38.0, 130, 26],\n",
    "                  [84, 132, 38.3, 146, 30],\n",
    "                  [78, 128, 37.2, 102, 12]])\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "print(X[0]) # this is patient-0 information which is a rank-1 tensor\n",
    "print(X[0, :]) # patient-0 all features\n",
    "print('------------')\n",
    "print(X[0, 2]) # feature-2 of patient-0, temperature of patient-0\n",
    "print(X[:, 2]) # feature-2 of all patients, temperature of all patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cevtn_b4gek5"
   },
   "source": [
    "---\n",
    "\n",
    "**Convert a PyTorch object into a numpy array**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrYQ2moygfPu"
   },
   "outputs": [],
   "source": [
    "print(X.numpy())\n",
    "print(type(X.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QS3MmzwsgkWU"
   },
   "source": [
    "---\n",
    "\n",
    "**Addition and subtraction of vectors, scalar multiplication (apply operation componentwise)**\n",
    "\n",
    "![vector addition](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3NokBAAAAAZLAaAoWwhtn8Vk26NotALo?width=256)\n",
    "\n",
    "![vector subtracton](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3M4kBAAAAAU_n_mAEv006QFZm_sUj2Dc?width=256)\n",
    "\n",
    "![vector multiplication](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3NIkBAAAAAa_qL04bLT4kWoNeHcrR9LQ?width=256)\n",
    "\n",
    "![vector geometry1](https://1drv.ms/i/c/37720f927b6ddc34/IQSGNMr5z3SSRry7LSKL7LybAcGYuzgw5smabV8-6DudXIs?width=230)\n",
    "\n",
    "![vector geometry2](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3WokBAAAAAQi8FPV9YCebl5WnyEKJ3vg?width=213&height=192)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgPtJP0sglQP"
   },
   "outputs": [],
   "source": [
    "# Vector addition\n",
    "print(X[1, :] + X[2, :])\n",
    "\n",
    "# Vector subtraction\n",
    "print(X[1, :] - X[2, :])\n",
    "\n",
    "# Scalar-vector multiplication\n",
    "print(X[:, 2])\n",
    "print((9/5)*X[:, 2]+32) # 0peration not defined in pen & paper but in computation is referred to as\n",
    "# broadcasting\n",
    "\n",
    "# Average patient\n",
    "x_avg = (1/6)*(X[0, :] + X[1, :] + X[2, :] + X[3, :] + X[4, :] + X[5, :])\n",
    "x_avg = torch.mean(X, dim = 0) # dim = 0 means top-to-bottom or along dim-0\n",
    "\n",
    "# Another broadcasting example\n",
    "print(X)\n",
    "print(x_avg)\n",
    "print(X - x_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1t_qXrlCROKA"
   },
   "source": [
    "---\n",
    "\n",
    "Application of vector subtraction in natural language processing (NLP): download the word embedding model trained on Wikipedia articles.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30817,
     "status": "ok",
     "timestamp": 1754024724682,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "_e13FnW0RUwy",
    "outputId": "68e640d0-1254-4074-cb93-4b62270cc6b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YRVJferRlK5"
   },
   "source": [
    "---\n",
    "\n",
    "Now we will see what embedding vector comes as a result of applying the model for the words *cricket* and *football*.\n",
    "\n",
    "Next, we will do an *intuitive* subtraction of word embeddings as in\n",
    "\n",
    "1. Cricket without Tendulkar\n",
    "2. Football without Messi\n",
    "\n",
    "Note that the embedding vectors have 50 components corresponding to the 50-dimensional embedding of model suggested by the name '**glove-wiki-gigaword-50**'\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1753936988958,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "HVVFzeQyR3Wb",
    "outputId": "545e5180-4933-446e-9a92-b10fa09afab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7716      0.41267997 -1.725968   -0.10445005 -1.1475699  -0.854661\n",
      " -1.089      -0.08342999  0.62349    -1.67822    -0.2488078  -0.49199998\n",
      "  0.18756002 -1.67098     0.6117872   0.42784432  1.05656     0.91583097\n",
      " -0.03299999 -0.04422501  0.200326   -0.33737004  0.31068     1.37842\n",
      " -1.13689    -0.57445    -0.70685995  0.41552    -0.28937     0.54485\n",
      "  1.0492998   0.62732    -0.8105     -1.27723    -0.02612001  0.53963\n",
      " -0.14065999 -0.738244   -0.30487    -1.18129     0.05651999 -0.993618\n",
      " -0.911399   -0.09289992  0.535432    0.26259995 -0.63031     0.64473\n",
      "  0.77843     0.15099996]\n",
      "[-2.06898     0.66804904 -1.077512    0.79964995 -0.27109998 -0.26289004\n",
      " -0.881       0.377503   -0.10869002 -2.47329    -0.23453003 -0.58438\n",
      "  0.10404003 -0.52671003 -0.03030002  0.237764    0.19168997  1.60344\n",
      " -0.42980003  0.59058     0.59800005 -0.67075     0.45888     1.4538\n",
      " -1.15642    -1.63534    -1.1248189  -0.20879    -0.00812     0.25545004\n",
      "  1.92044     0.30049008  0.19949001 -0.675167   -0.15230002  0.13278002\n",
      " -0.29492003 -0.55414    -0.30988902 -0.34549004 -0.72603    -1.20504\n",
      " -0.45038998  0.51834     0.12448996  0.787596   -1.13398     0.91365004\n",
      " -0.280479    0.76741004]\n",
      "[ 1.29738    -0.25536907 -0.648456   -0.9041     -0.8764699  -0.59177095\n",
      " -0.208      -0.460933    0.73218     0.79506993 -0.01427777  0.09237999\n",
      "  0.08352    -1.14427     0.6420872   0.19008031  0.8648701  -0.6876091\n",
      "  0.39680004 -0.63480496 -0.39767405  0.33337998 -0.1482     -0.07537997\n",
      "  0.01952994  1.06089     0.41795897  0.62431    -0.28125     0.28939995\n",
      " -0.8711401   0.3268299  -1.00999    -0.602063    0.12618001  0.40684998\n",
      "  0.15426004 -0.18410403  0.00501901 -0.8358      0.78255     0.21142197\n",
      " -0.46100903 -0.6112399   0.41094202 -0.52499604  0.50367004 -0.26892006\n",
      "  1.0589089  -0.6164101 ]\n"
     ]
    }
   ],
   "source": [
    "# Cricket without Tendulkar\n",
    "a = model['cricket'] - model['tendulkar']\n",
    "\n",
    "# Football without Messi\n",
    "b = model['football'] - model['messi']\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# How different is cricket-without-tendulkar from\n",
    "# football-without-messi?\n",
    "print(a-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VPICS8ggvvg"
   },
   "source": [
    "---\n",
    "\n",
    "A tensor of rank 3 corresponding to 4 time stamps (hourly), 3 samples (patients), 2 features (HR and BP). Assume that admission time is 9AM.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1754271459743,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "yQAvgkRkWAM8",
    "outputId": "9c0693b4-b4a5-4de9-ca11-0d40fed767c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 74., 128.],\n",
      "         [ 79., 116.],\n",
      "         [ 71., 116.]],\n",
      "\n",
      "        [[ 78., 118.],\n",
      "         [ 82., 124.],\n",
      "         [ 72., 128.]],\n",
      "\n",
      "        [[ 84., 138.],\n",
      "         [ 84., 130.],\n",
      "         [ 74., 120.]],\n",
      "\n",
      "        [[ 82., 126.],\n",
      "         [ 76., 156.],\n",
      "         [ 82., 132.]]])\n"
     ]
    }
   ],
   "source": [
    "# A rank-3 patient tensor with shape (4, 3, 2)\n",
    "# with meaning for\n",
    "# dim-0 as 4 hourly timestamps,\n",
    "# dim-1 as 3 patients, and\n",
    "# dim-2 as 2 features (HR and BP)\n",
    "# T = torch.tensor([[[HR, BP], [HR, BP], [HR, BP]],\n",
    "#                   [[HR, BP], [HR, BP], [HR, BP]],\n",
    "#                   [[HR, BP], [HR, BP], [HR, BP]],\n",
    "#                   [[HR, BP], [HR, BP], [HR, BP]]])\n",
    "T = torch.tensor([[[74., 128], [79, 116], [71, 116]],\n",
    "                 [[78, 118], [82, 124], [72, 128]],\n",
    "                 [[84, 138], [84, 130], [74, 120]],\n",
    "                 [[82, 126], [76, 156], [82, 132]]])\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV0fpSojg2EZ"
   },
   "source": [
    "---\n",
    "\n",
    "**Accessing elements of a tensor**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1754271466289,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "1GbZuDYqg22n",
    "outputId": "d2de34bf-52ec-4a94-ad18-553010e0a485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(132.)\n",
      "tensor([[ 74., 128.],\n",
      "        [ 79., 116.],\n",
      "        [ 71., 116.]])\n",
      "tensor([[ 82., 126.],\n",
      "        [ 76., 156.],\n",
      "        [ 82., 132.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 82., 132.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Accessing elements of a tensor\n",
    "# Rank-3 tensor T has axes order (timestamps, patients, features)\n",
    "\n",
    "# Element of T at postion 3 w.r.t. dim-0, position 2 w.r.t. dim-1,\n",
    "# position-1 w.r.t dim-2\n",
    "print(T[3, 2, 1])  # BP of patient-2 at noon\n",
    "\n",
    "\n",
    "# Element-0 of object T which is also the info for all patients at\n",
    "# admission time 9AM\n",
    "print(T[0]) # patients' info at admission time\n",
    "print(T[-1])\n",
    "\n",
    "\n",
    "# Patient-2 info at noon\n",
    "T[-1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW2_NDTCjIL5"
   },
   "source": [
    "---\n",
    "\n",
    "**Broadcasting**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1753940756070,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "1PjnkDnr_qSn",
    "outputId": "731244d1-930a-4a20-f95c-10d04055d611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "tensor([-3., -2., -1.])\n"
     ]
    }
   ],
   "source": [
    "# A simple broadcasting example\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0])\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1754271471991,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "zhtxw34i_RNt",
    "outputId": "b8338d57-5d76-4b97-eb72-e70adc90b995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 74., 128.],\n",
      "        [ 78., 118.],\n",
      "        [ 84., 138.],\n",
      "        [ 82., 126.]])\n",
      "torch.Size([4, 2])\n",
      "--------------\n",
      "tensor([[[ 74., 128.]],\n",
      "\n",
      "        [[ 78., 118.]],\n",
      "\n",
      "        [[ 84., 138.]],\n",
      "\n",
      "        [[ 82., 126.]]])\n",
      "torch.Size([4, 1, 2])\n",
      "-------------\n",
      "tensor([[[ 74., 128.],\n",
      "         [ 79., 116.],\n",
      "         [ 71., 116.]],\n",
      "\n",
      "        [[ 78., 118.],\n",
      "         [ 82., 124.],\n",
      "         [ 72., 128.]],\n",
      "\n",
      "        [[ 84., 138.],\n",
      "         [ 84., 130.],\n",
      "         [ 74., 120.]],\n",
      "\n",
      "        [[ 82., 126.],\n",
      "         [ 76., 156.],\n",
      "         [ 82., 132.]]])\n"
     ]
    }
   ],
   "source": [
    "# How to add a new axis to a tensor using the unsqueeze() method\n",
    "T_p0 = T[:,0,:]\n",
    "print(T_p0)\n",
    "print(T_p0.shape)\n",
    "print(\"--------------\")\n",
    "T_p0_new=torch.unsqueeze(T_p0,1)\n",
    "print(T_p0_new)\n",
    "print(T_p0_new.shape)\n",
    "print(\"-------------\")\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1753940090541,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "DEPPWVsWjI4X",
    "outputId": "5db7ae23-c0c8-49ed-9103-907f69d0ae4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0.,   0.],\n",
      "         [  5., -12.],\n",
      "         [ -3., -12.]],\n",
      "\n",
      "        [[  0.,   0.],\n",
      "         [  4.,   6.],\n",
      "         [ -6.,  10.]],\n",
      "\n",
      "        [[  0.,   0.],\n",
      "         [  0.,  -8.],\n",
      "         [-10., -18.]],\n",
      "\n",
      "        [[  0.,   0.],\n",
      "         [ -6.,  30.],\n",
      "         [  0.,   6.]]])\n"
     ]
    }
   ],
   "source": [
    "# How different are the patients from patient-0?\n",
    "#T - T[:, 0, :] # does not work for broadcasting\n",
    "print(T-T_p0_new)\n",
    "\n",
    "#  # How different are the patients compared to their time at admission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o6kEXfCpDzo"
   },
   "source": [
    "---\n",
    "\n",
    "**Exercise**: interpret $\\texttt{T[:, -1, :]}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1753940933983,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "X6lEPZEWo6wo",
    "outputId": "5839a4f4-bddf-4da7-cd0d-0a8cc3d28677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1, -3,  3],\n",
      "         [ 0, -4, -4],\n",
      "         [ 3,  2, -5],\n",
      "         [-3,  2, -5],\n",
      "         [-5,  2, -1]],\n",
      "\n",
      "        [[-5,  1, -1],\n",
      "         [ 1,  0, -3],\n",
      "         [ 3,  1,  0],\n",
      "         [ 5,  4,  0],\n",
      "         [ 2,  4, -2]],\n",
      "\n",
      "        [[ 5,  1,  1],\n",
      "         [ 5, -2, -3],\n",
      "         [-4, -2, -4],\n",
      "         [-2, -5, -3],\n",
      "         [ 0, -1,  1]],\n",
      "\n",
      "        [[ 2,  0,  4],\n",
      "         [-3,  5, -1],\n",
      "         [-3,  0, -5],\n",
      "         [-4,  5, -5],\n",
      "         [-5, -5,  5]]])\n",
      "tensor([1., 2., 3.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Last patient's info at all timestamps\n",
    "# t_pl=torch.unsqueeze(T[:,-1,:],1)\n",
    "# t_pl\n",
    "T= torch.randint(-5,6,(4,5,3))\n",
    "print(T)\n",
    "v = torch.tensor([1.0,2.0,3.0])\n",
    "print(v)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gc9EJuZQhD9i"
   },
   "source": [
    "---\n",
    "\n",
    "$l_2$ norm or the geometric length of a vector denoted as $\\lVert \\mathbf{a}\\rVert$ tells us how long a vector is. In 2-dimensions, $$\\lVert \\mathbf{a}\\rVert_2 = \\sqrt{a_1^2+a_2^2}$$ and in $n$-dimensions, $$\\lVert \\mathbf{a}\\rVert_2 = \\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}.$$\n",
    "\n",
    "![vector norm](https://1drv.ms/i/c/37720f927b6ddc34/IQT817WmpQjlRqZ1R0d5Cfv6AUW6c4robL-gk06i9wmCaFU?width=500)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1753944487396,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "OM65UP4_hEso",
    "outputId": "7aaf5dcc-844e-4b13-854d-eb21168c6068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 76., 124.], dtype=torch.float64)\n",
      "tensor(145.4373, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## l2 norm of a vector\n",
    "x = torch.tensor([76,124],dtype=torch.float64)\n",
    "print(x)\n",
    "print(torch.norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRbanrUmwLX7"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Dot Product of Vectors**\n",
    "\n",
    "A scalar resulting from an elementwise multiplication and addition: $$\\mathbf{a}{\\color{cyan}\\cdot}\\mathbf{b} = {\\color{red}{a_1b_1}}+{\\color{green}{a_2b_2}}+\\cdots+{\\color{magenta}{a_nb_n}}$$\n",
    "\n",
    "The <font color=\"cyan\">dot</font> ${\\color{cyan}\\cdot}$ represents the computation of the dot product.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1753946654364,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "s91XY1JZwU2w",
    "outputId": "40380453-e114-48ac-9703-7c9e2ca752d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32., dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dot product of vectors\n",
    "a = torch.tensor([1.0, 2.0, 3.0],dtype=torch.float64)\n",
    "b = torch.tensor([4.0, 5.0, 6.0],dtype=torch.float64)\n",
    "torch.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-b90m-QXyFp"
   },
   "source": [
    "---\n",
    "\n",
    "The dot product is a measure of similarity between vectors (or, how aligned they are geometrically).\n",
    "\n",
    "![dot product](https://1drv.ms/i/c/37720f927b6ddc34/IQTbcGSjdbhSTJ7J39d5BCWAAWS6-y5U6J87vHuDWeAqGwM?width=6000)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GxZ95uXXz3P"
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([1.0, 2.0])\n",
    "b = torch.tensor([2.0, 4.0])\n",
    "c = torch.tensor([-2.0, 1.0])\n",
    "d = torch.tensor([-1.0, -2.0])\n",
    "print(torch.dot(a, b))\n",
    "print(torch.dot(a, c))\n",
    "print(torch.dot(a, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6CS4_8byCs8"
   },
   "source": [
    "---\n",
    "\n",
    "Cauchy-Schwarz inequality $-1\\leq\\frac{\\mathbf{x}\\cdot{\\mathbf{y}}}{\\lVert\\mathbf{x}\\rVert_2\\lVert\\mathbf{y}\\rVert_2}\\leq1.$\n",
    "\n",
    "This is a normalized measure of similarity (or extent of alignment) between vectors.\n",
    "\n",
    "Angle between vectors $\\mathbf{x}$ and $\\mathbf{y} = \\cos^{-1}\\left(\\frac{\\mathbf{x}\\cdot{\\mathbf{y}}}{\\lVert\\mathbf{x}\\rVert_2\\lVert\\mathbf{y}\\rVert_2}\\right).$\n",
    "\n",
    "![angle](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3WokBAAAAAQi8FPV9YCebl5WnyEKJ3vg?width=213&height=400)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1754024888938,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "mlzesZASBkKz",
    "outputId": "b6429206-cff4-4ba1-e0f6-7cec4acd71ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "torch.Size([3])\n",
      "------------\n",
      "tensor([[1., 2., 3.]])\n",
      "torch.Size([1, 3])\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "a= torch.tensor([1.0,2.0,3.0])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(\"------------\")\n",
    "a= torch.tensor([[1.0,2.0,3.0]])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1754026311155,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "q4UhBnPUx7TV",
    "outputId": "5a2d4c31-5000-4e49-f8b7-b329b6629325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4142, dtype=torch.float64)\n",
      "0.6435011087932847\n",
      "36.86989764584404\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0], dtype=torch.float64)\n",
    "y = torch.tensor([2.0, 1.0], dtype=torch.float64)\n",
    "print(torch.norm(x - y))\n",
    "# Angle between x and y in radians\n",
    "d=torch.dot(x,y)\n",
    "c=torch.norm(x)*torch.norm(y)\n",
    "f=d/c\n",
    "r = math.acos(f)\n",
    "print(r)\n",
    "# Angle between x and y in degrees\n",
    "print(math.degrees(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bnmEkg3Tctx"
   },
   "source": [
    "---\n",
    "\n",
    "Application of the Cauchy-Schwarz inequality: is \"Cricket without Tendulkar\" same as \"Football without Messi\"?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1754025128531,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "KrmCknO5TkNZ",
    "outputId": "a5f0df99-6869-483d-b4a7-6d114df48906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n",
      "0.7419853940459407\n",
      "42.51263153918372\n"
     ]
    }
   ],
   "source": [
    "a = model['cricket'] - model['tendulkar']\n",
    "b = model['football'] - model['messi']\n",
    "print(type(a))\n",
    "x=torch.tensor(a)\n",
    "y=torch.tensor(b)\n",
    "print(type(x))\n",
    "d=torch.dot(x,y)\n",
    "n= torch.norm(x)*torch.norm(y)\n",
    "f=d/n\n",
    "r=math.acos(f)\n",
    "print(r)\n",
    "print(math.degrees(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "error",
     "timestamp": 1754027313521,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "MJtQ7DLrHoTB",
    "outputId": "3eb559e5-06b6-4f85-c1e0-abd66a755481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dot : expected both vectors to have same dtype, but found Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4217718056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# print((180.0/torch.pi)*torch.acos(torch.dot(x,c)/(torch.norm(x)*torch.norm(c))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot : expected both vectors to have same dtype, but found Double and Float"
     ]
    }
   ],
   "source": [
    "c= model['tennis'] - model['federer']\n",
    "z=torch.tensor(c)\n",
    "print(type(x))\n",
    "print(type(z))\n",
    "torch.dot(x,z)\n",
    "# print((180.0/torch.pi)*torch.acos(torch.dot(x,c)/(torch.norm(x)*torch.norm(c))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayzM_0_synRF"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Hadamard Product of Vectors**\n",
    "\n",
    "A vector resulting from an elementwise multiplication: $$\\mathbf{a}{\\color{cyan}\\otimes}\\mathbf{b} = \\begin{bmatrix}{\\color{red}{a_1\\times b_1}}\\\\{\\color{green}{a_2\\times b_2}}\\\\\\vdots\\\\{\\color{magenta}{a_n\\times b_n}}\\end{bmatrix}.$$\n",
    "\n",
    "The <font color=\"cyan\">$\\otimes$</font> represents the computation of the Hadamard product.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1753946443649,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "UPojS0rIzR8p",
    "outputId": "0eb2f182-c5b3-473e-a38c-8134f013cbf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.], dtype=torch.float64)\n",
      "tensor([ 4., 10., 18.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## Hadamard product\n",
    "a = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float64)\n",
    "b = torch.tensor([4.0, 5.0, 6.0], dtype=torch.float64)\n",
    "\n",
    "# Element-wise multiplication (Hadamard product)\n",
    "print(a*b)\n",
    "print(torch.mul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oruyV_EjhqCR"
   },
   "source": [
    "---\n",
    "\n",
    "A matrix-vector product is simply a sequence of dot products of the rows of the matrix (seen as vectors) with the vector\n",
    "\n",
    "![matvec product](https://1drv.ms/i/c/37720f927b6ddc34/IQQ1cQ8fZdFmS4cnGkBlsZbAAaL2zMtzWdjHe-HCMt4UTA0?width=700)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1754027859632,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "A_IScSWzhpi7",
    "outputId": "ebfdf03b-7ed3-43f4-8524-58d7d68223ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "## Matrix-vector product\n",
    "A = torch.tensor([[1.0, 2.0, 4.0],\n",
    "                  [2.0, -1.0, 3.0]])\n",
    "x = torch.tensor([4.0, 2.0, -2.0])\n",
    "\n",
    "# Matrix-vector multiplication\n",
    "print(torch.matmul(A,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1754032698455,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "v8XccGlAcs0R",
    "outputId": "062adc45-309e-494a-c82e-21d1eb28d603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.6603, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## Matrix-vector product\n",
    "A = torch.tensor([[1,-2,1,0,0,0],\n",
    "                  [0,1,-2,1,0,0],\n",
    "                  [0,0,1,-2,1,0],\n",
    "                  [0,0,0,1,-2,1]], dtype=torch.float64)\n",
    "x = torch.tensor([10,15,25,35,40,50], dtype=torch.float64)\n",
    "\n",
    "# Matrix-vector multiplication\n",
    "print(torch.norm(torch.matmul(A,x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1754032869157,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "r46sk3aoewcU",
    "outputId": "905bf70c-2982-4d51-de29-d6c3f8a45844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(85.4400, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## Matrix-vector product\n",
    "A = torch.tensor([[1,-2,1,0,0,0],\n",
    "                  [0,1,-2,1,0,0],\n",
    "                  [0,0,1,-2,1,0],\n",
    "                  [0,0,0,1,-2,1]], dtype=torch.float64)\n",
    "x = torch.tensor([10,-5,15,-10,10,-15], dtype=torch.float64)\n",
    "\n",
    "# Matrix-vector multiplication\n",
    "print(torch.norm(torch.matmul(A,x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTnGSJ3vT4EN"
   },
   "source": [
    "---\n",
    "\n",
    "Here we create a simple sentence in English and tokenize it\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQ73kkevT5L3"
   },
   "outputs": [],
   "source": [
    "sentence = 'i swam quickly across the river to get to the other bank'\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M40pqI8UUbX4"
   },
   "source": [
    "---\n",
    "\n",
    "Generate the word embeddings for the tokens and store them in a matrix $\\mathbf{X}$ such that each row of the matrix corresponds to a token.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mKKVRyxUh5V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z0pZQisxtY-"
   },
   "source": [
    "---\n",
    "\n",
    "A matrix-matrix product is simply a sequence of matrix-vector products.\n",
    "\n",
    "![matmatprod](https://1drv.ms/i/c/37720f927b6ddc34/IQQ-B3z7tbWHQqBrW9k2ElDVAUc5fWzM24txLkgBK7f8Yac?width=550)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSg1brJ9yKnM"
   },
   "outputs": [],
   "source": [
    "## Matrix-matrix product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5cHHVQOuT0z"
   },
   "source": [
    "---\n",
    "\n",
    "Matrix-matrix product using patient data matrix and a weights matrix:\n",
    "\n",
    "![patient dataset](https://1drv.ms/i/s!AjTcbXuSD3I3hspfrgklysOtJMOjaA?embed=1&width=800)\n",
    "\n",
    "$$\\mathbf{Z} = \\mathbf{XW}.$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1754372333167,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "njrrw_MnuUpo",
    "outputId": "b515a1c9-1a33-42ac-f711-38c2c1bd345d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient data matrix X:\n",
      " tensor([[ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000],\n",
      "        [ 85.0000, 130.0000,  37.0000, 110.0000,  14.0000],\n",
      "        [ 68.0000, 110.0000,  38.5000, 125.0000,  34.0000],\n",
      "        [ 90.0000, 140.0000,  38.0000, 130.0000,  26.0000],\n",
      "        [ 84.0000, 132.0000,  38.3000, 146.0000,  30.0000],\n",
      "        [ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000]],\n",
      "       dtype=torch.float64)\n",
      "Weights matrix:\n",
      " tensor([[-0.1000,  0.5000,  0.3000],\n",
      "        [ 0.9000,  0.3000,  0.5000],\n",
      "        [-1.5000,  0.4000,  0.1000],\n",
      "        [ 0.1000,  0.1000, -1.0000],\n",
      "        [-1.2000,  0.5000, -0.8000]], dtype=torch.float64)\n",
      "Raw zcores matrix:\n",
      " tensor([[ 16.2500, 113.5700, -44.6700],\n",
      "        [ 47.2000, 114.3000, -27.0000],\n",
      "        [  6.1500, 111.9000, -72.9500],\n",
      "        [ 41.8000, 128.2000, -50.0000],\n",
      "        [ 31.5500, 126.5200, -74.9700],\n",
      "        [ 47.4000, 108.4800, -20.4800]], dtype=torch.float64)\n",
      "softmax scores: \n",
      " tensor([[5.4258e-43, 1.0000e+00, 1.8934e-69],\n",
      "        [7.2250e-30, 1.0000e+00, 4.3071e-62],\n",
      "        [1.1840e-46, 1.0000e+00, 5.2561e-81],\n",
      "        [2.9989e-38, 1.0000e+00, 4.0618e-78],\n",
      "        [5.6892e-42, 1.0000e+00, 3.1189e-88],\n",
      "        [2.9737e-27, 1.0000e+00, 9.8488e-57]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Patients data matrix\n",
    "X = torch.tensor([[72, 120, 37.3, 104, 32.5],\n",
    "                 [85, 130, 37.0, 110, 14],\n",
    "                 [68, 110, 38.5, 125, 34],\n",
    "                 [90, 140, 38.0, 130, 26],\n",
    "                 [84, 132, 38.3, 146, 30],\n",
    "                 [78, 128, 37.2, 102, 12]],dtype=torch.float64)\n",
    "print(f'Patient data matrix X:\\n {X}')\n",
    "\n",
    "# Weights matrix\n",
    "W =torch.tensor([[-0.1,0.5,0.3],\n",
    "                 [0.9,0.3,0.5],\n",
    "                 [-1.5,0.4,0.1],\n",
    "                 [0.1,0.1,-1.0],\n",
    "                 [-1.2,0.5,-0.8]], dtype=torch.float64)\n",
    "print(f'Weights matrix:\\n {W}')\n",
    "\n",
    "# Raw scores matrix (matrix-matrix multiplication)\n",
    "Z = torch.matmul(X,W)\n",
    "print(f'Raw zcores matrix:\\n {Z}')\n",
    "# The raw scores are also referred to as the logits\n",
    "\n",
    "softmax=torch.nn.Softmax(dim=1)\n",
    "A=softmax(Z)\n",
    "print(f\"softmax scores: \\n {A}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWigLvBRucwi"
   },
   "source": [
    "---\n",
    "\n",
    "**Version-1** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n",
    "\n",
    "*What a particular neuron understands about a particular patient.*\n",
    "\n",
    "![matrix-matrix product version-1](https://1drv.ms/i/c/37720f927b6ddc34/IQQdAOCwtndURKA-h4yvpTqlAYjBjlcweRSeMYkPvf7dwmQ?width=660)\n",
    "\n",
    "$$\\begin{align*}[\\mathbf{Z}]_{i,j} &= (i,j)\\text{-th element of }\\mathbf{Z}\\\\&=\\text{what the }j\\text{th neuron learns about the } i\\text{th patient}\\\\&=\\mathbf{x}^{(i)}\\cdot\\mathbf{w}_j\\\\& = {\\mathbf{x}^{(i)}}^\\mathrm{T}\\mathbf{w}_j\\\\\\Rightarrow \\underbrace{[\\mathbf{Z}]_{{\\color{yellow}0},{\\color{cyan}2}}}_{{\\color{yellow}0}\\text{th patient},\\,{\\color{cyan}2}\\text{nd neuron}} &= \\mathbf{x}^{({\\color{yellow}0})}\\cdot\\mathbf{w}_{{\\color{cyan}2}}\\\\ &= \\begin{bmatrix}72\\\\120\\\\37.3\\\\104\\\\32.5\\end{bmatrix}\\cdot\\begin{bmatrix}0.3\\\\0.5\\\\0.1\\\\-1.0\\\\-0.8\\end{bmatrix}\\\\ &= -44.67.\\end{align*}$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1754272348521,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "q-rGT4NaueRk",
    "outputId": "d7eb2a3d-6c0a-410f-c83d-ead22061019c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "tensor(-44.6700, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## The (0, 2)-th element of the matrix-matrix product XW\n",
    "Z02 = torch.dot(X[0],W[:,2])\n",
    "print(X[0].shape)\n",
    "print(W[:,2].shape)\n",
    "print(Z02)\n",
    "## the second neuro's understanding of the paitent 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzqALUS-ugoU"
   },
   "source": [
    "---\n",
    "\n",
    "**Version-2** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n",
    "\n",
    "*What a particular neuron understands about all the patients.*\n",
    "\n",
    "![matrix-matrix product version-2](https://1drv.ms/i/c/37720f927b6ddc34/IQRm1-w-6TG0R4C4J4BizyzyAWIbcHzbEjgmx-0JFREdHsE?width=660)\n",
    "\n",
    "$$\\begin{align*}\\mathbf{z}_j &= \\mathbf{X}\\mathbf{w}_j\\\\&=\\text{what the } j\\text{th neuron learns about the all the patients}\\\\&=w_{j,0}\\times\\textbf{HR}+w_{j,1}\\times\\textbf{BP}+w_{j,2}\\times\\textbf{Temp}+w_{j,3}\\times\\textbf{Sugar}+w_{j,4}\\times\\textbf{Vitamin D}\\\\&= w_{j,0}\\mathbf{x}_0+w_{j,1}\\mathbf{x}_1+w_{j,2}\\mathbf{x}_2+w_{j,3}\\mathbf{x}_3+w_{j,4}\\mathbf{x}_4\\\\\\Rightarrow\\underbrace{\\mathbf{z}_{{\\color{cyan}0}}}_{{\\color{cyan}0}\\text{th neuron understanding}} &= \\underbrace{\\mathbf{X}}_{\\color{yellow}{\\text{all patients}}}\\ \\underbrace{\\mathbf{w}_{{\\color{cyan}0}}}_{{\\color{cyan}0}\\text{th neuron weights}}\\\\&= {\\color{cyan}{-0.1}}\\times\\begin{bmatrix}{\\color{yellow}{72}}\\\\{\\color{yellow}{85}}\\\\{\\color{yellow}{68}}\\\\{\\color{yellow}{90}}\\\\{\\color{yellow}{84}}\\\\{\\color{yellow}{78}}\\end{bmatrix}+{\\color{cyan}{0.9}}\\times\\begin{bmatrix}{\\color{yellow}{120}}\\\\{\\color{yellow}{130}}\\\\{\\color{yellow}{110}}\\\\{\\color{yellow}{140}}\\\\{\\color{yellow}{132}}\\\\{\\color{yellow}{128}}\\end{bmatrix}+({\\color{cyan}{-1.5}})\\times\\begin{bmatrix}{\\color{yellow}{37.3}}\\\\{\\color{yellow}{37.0}}\\\\{\\color{yellow}{38.5}}\\\\{\\color{yellow}{38.0}}\\\\{\\color{yellow}{38.3}}\\\\{\\color{yellow}{37.2}}\\end{bmatrix}+{\\color{cyan}{0.1}}\\times\\begin{bmatrix}{\\color{yellow}{104}}\\\\{\\color{yellow}{110}}\\\\{\\color{yellow}{125}}\\\\{\\color{yellow}{130}}\\\\{\\color{yellow}{146}}\\\\{\\color{yellow}{102}}\\end{bmatrix}+({\\color{cyan}{-1.2}})\\times\\begin{bmatrix}{\\color{yellow}{32.5}}\\\\{\\color{yellow}{14}}\\\\{\\color{yellow}{34}}\\\\{\\color{yellow}{26}}\\\\{\\color{yellow}{30}}\\\\{\\color{yellow}{12}}\\end{bmatrix}\\\\&=\\begin{bmatrix}16.25\\\\47.20\\\\6.15\\\\41.80\\\\31.55\\\\47.40\\end{bmatrix}.\\end{align*}$$\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1754272377413,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "sJbmVTzuukEh",
    "outputId": "84be4f3d-8de3-4f7b-d9e4-bdc14a75ab1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5])\n",
      "torch.Size([5])\n",
      "tensor([16.2500, 47.2000,  6.1500, 41.8000, 31.5500, 47.4000],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## The 0-th column of the matrix-matrix product XW\n",
    "ZA0=torch.matmul(X,W[:,0])\n",
    "print(X.shape)\n",
    "print(W[:,0].shape)\n",
    "print(ZA0)\n",
    "## the understanding of all the paitents by the first neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrQE8b2xukgE"
   },
   "source": [
    "---\n",
    "\n",
    "**Version-3** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n",
    "\n",
    "*What all neurons understand about a particular patient.*\n",
    "\n",
    "![matrix-matrix product version-3](https://1drv.ms/i/c/37720f927b6ddc34/IQRfO-qEJQ9mQYLH_f-lyjeQAaWV4FrDjTjaEHJpPB1PmCg?width=660)\n",
    "\n",
    "$$\\begin{align*}{\\mathbf{z}^{(i)}}^\\mathrm{T}&={\\mathbf{x}^{(i)}}^\\mathrm{T}\\mathbf{W}\\\\&= \\text{what is learned about the }i\\text{th patient by all the neurons}\\\\&=i\\text{th HR }\\times{\\mathbf{w}^{(0)}}^\\mathrm{T}+i\\text{th BP }\\times{\\mathbf{w}^{(1)}}^\\mathrm{T}+i\\text{th Temp }\\times{\\mathbf{w}^{(2)}}^\\mathrm{T}+i\\text{th Sugar }\\times{\\mathbf{w}^{(3)}}^\\mathrm{T}+i\\text{th Vitamin D }\\times{\\mathbf{w}^{(4)}}^\\mathrm{T}\\\\&=x^{(i)}_0\\times{\\mathbf{w}^{(0)}}^\\mathrm{T}+x^{(i)}_1\\times{\\mathbf{w}^{(1)}}^\\mathrm{T}+x^{(i)}_2\\times{\\mathbf{w}^{(2)}}^\\mathrm{T}+x^{(i)}_3\\times{\\mathbf{w}^{(3)}}^\\mathrm{T}+x^{(i)}_4\\times{\\mathbf{w}^{(4)}}^\\mathrm{T}\\\\\\underbrace{\\Rightarrow{{\\mathbf{z}^{({\\color{yellow}0})}}^\\mathrm{T}}}_{{\\color{yellow}{0}}\\text{th patient understanding}}&=\\underbrace{{{\\mathbf{x}^{({\\color{yellow}0})}}^\\mathrm{T}}}_{{\\color{yellow}{0}}\\text{th patient}}\\ \\underbrace{\\mathbf{W}}_{{\\color{cyan}{\\text{all neurons}}}}\\\\ &= {\\color{yellow}{72}}\\times\\begin{bmatrix}{\\color{cyan}{-0.1}} & {\\color{cyan}{0.5}} & {\\color{cyan}{0.3}}\\end{bmatrix} \\\\&+ {\\color{yellow}{120}}\\times\\begin{bmatrix}{\\color{cyan}{0.9}} & {\\color{cyan}{0.3}} & {\\color{cyan}{0.5}}\\end{bmatrix}\\\\&+{\\color{yellow}{37.3}}\\times\\begin{bmatrix}{\\color{cyan}{-1.5}} & {\\color{cyan}{0.4}} & {\\color{cyan}{0.1}}\\end{bmatrix}\\\\&+{\\color{yellow}{104}}\\times\\begin{bmatrix}{\\color{cyan}{0.1}} & {\\color{cyan}{0.1}} & {\\color{cyan}{-1.0}}\\end{bmatrix}\\\\&+{\\color{yellow}{32.5}}\\times\\begin{bmatrix}{\\color{cyan}{-1.2}} & {\\color{cyan}{0.5}} & {\\color{cyan}{-0.8}}\\end{bmatrix}\\\\&=\\begin{bmatrix}16.25 & 113.57 & 7.33\\end{bmatrix}.\\end{align*}$$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1754272473343,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "o-Nv7NOLun5e",
    "outputId": "da859634-295a-4b79-908d-00ba433fe04b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([5, 3])\n",
      "tensor([ 16.2500, 113.5700, -44.6700], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## The 0-th row of the matrix-matrix product XW\n",
    "Z0A=torch.matmul(X[0],W)\n",
    "print(X[0].shape)\n",
    "print(W.shape)\n",
    "print(Z0A)\n",
    "## Understanding of paitent 0 by all neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVoJRc6kUtI2"
   },
   "source": [
    "---\n",
    "\n",
    "The similarity between each pair of words represented in the word embeddings matrix $\\mathbf{X}_\\mathrm{word}$ is the matrix-matrix product $\\mathbf{X}_\\mathrm{word}\\mathbf{X}_\\mathrm{word}^\\mathrm{T}.$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1754264106278,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "ms9Qg5AoVJy_",
    "outputId": "ece42af6-5e27-4113-d50c-14c644236164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n",
      "tensor([0.0900, 0.2447, 0.6652], dtype=torch.float64)\n",
      "tensor(1.0000, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "z = torch.tensor([1.0,2.0,3.0], dtype=torch.float64)\n",
    "print(z)\n",
    "softmax=torch.nn.Softmax(dim=0)\n",
    "a= softmax(z)\n",
    "print(a)\n",
    "print(torch.sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLWq_5p3usNO"
   },
   "source": [
    "---\n",
    "\n",
    "The softmax function: takes a $k$-vector $\\mathbf{z}$ as input and returns a vector $\\mathbf{a}$ of the same shape as the output which is referred to as the softmax-activated scores.\n",
    "\n",
    "$\\begin{align*}\\mathbf{a}&=\\text{softmax}(\\mathbf{z})=\\begin{bmatrix}\\dfrac{e^{z_1}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\\\\\dfrac{e^{z_2}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\\\\\vdots\\\\\\dfrac{e^{z_k}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\end{bmatrix}.\\end{align*}$\n",
    "\n",
    "In the following example, we consider a raw scores vector $\\mathbf{z}$ with 3 components which leads to the softmax-activated scores vectors $\\mathbf{a}$ which can be interpreted as the predicted probabilities that the sample belongs to each one of the output classes:\n",
    "\n",
    "![softmax](https://1drv.ms/i/s!AjTcbXuSD3I3hscmdol7J2G4GDo5WQ?embed=1&width=660)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1754373844771,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "kjB15RwpmSZ9",
    "outputId": "1eff5061-088e-4823-dc34-dae8ca4305d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr vector:\n",
      "tensor([72., 85., 68., 90., 84., 78.], dtype=torch.float64)\n",
      "bp vector:\n",
      "tensor([72., 85., 68., 90., 84., 78.], dtype=torch.float64)\n",
      "tensor(79.5000, dtype=torch.float64)\n",
      "average hr_mc:\n",
      "0.0\n",
      "Squared deviation in heart rate vecti=or:\n",
      "tensor([ 56.2500,  30.2500, 132.2500, 110.2500,  20.2500,   2.2500],\n",
      "       dtype=torch.float64)\n",
      "squared devation or varience:58.583333333333336\n",
      "standard devation:7.65397500213669\n",
      "Z score:\n",
      " tensor([-0.9799,  0.7186, -1.5025,  1.3718,  0.5879, -0.1960],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#heart rate vector\n",
    "a=X[:,0]\n",
    "print(f'hr vector:\\n{a}')\n",
    "\n",
    "b=X[:,0]\n",
    "print(f'bp vector:\\n{b}')\n",
    "\n",
    "print(torch.mean(a))\n",
    "\n",
    "#mean centred hr or de-meanded hr\n",
    "hr_mc= a-torch.mean(a)\n",
    "\n",
    "print(f'average hr_mc:\\n{torch.mean(hr_mc)}')\n",
    "\n",
    "print(f'Squared deviation in heart rate vecti=or:\\n{hr_mc**2}')\n",
    "\n",
    "v=torch.mean(hr_mc**2)\n",
    "print(f'squared devation or varience:{v}')\n",
    "\n",
    "\n",
    "s= torch.sqrt(v)\n",
    "print(f'standard devation:{s}')\n",
    "\n",
    "print(f'Z score:\\n {hr_mc/s}')\n",
    "\n",
    "#standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1754377142846,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "-Zn1EXtqmeFy",
    "outputId": "1d487362-039d-4844-aa62-3f8ea84d7594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "[1.0, 2.0, 3.0]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#the followign is not possible in np\n",
    "#y=toruch.tesor([\"\",\"\"])\n",
    "\n",
    "b=np.array([1.0,2.0,3.0])\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(type(b))\n",
    "\n",
    "c=[1.0,2.0,3.0]\n",
    "print(c)\n",
    "# print(c.shape)\n",
    "print(type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1754379274490,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "7n5BscQkBxZq",
    "outputId": "23384180-0c10-4094-d1cd-9a1b09c39ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nd' 'd' 'nd' 'pd' 'd' 'pd']\n",
      "(6,)\n",
      "[['nd']\n",
      " ['d']\n",
      " ['nd']\n",
      " ['pd']\n",
      " ['d']\n",
      " ['pd']]\n",
      "(6, 1)\n",
      "tensor([[0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y=np.array(['nd','d','nd','pd','d','pd'])\n",
    "print(y)\n",
    "print(y.shape)\n",
    "v=y.reshape(-1,1)\n",
    "print(v)\n",
    "print(v.shape)\n",
    "\n",
    "ohe=OneHotEncoder(sparse_output=False)\n",
    "Y=torch.tensor(ohe.fit_transform(v))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1754378514211,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "VHMgAQxnF4_D",
    "outputId": "f6715f02-f388-4458-aa5a-11179c99ec60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9799, -0.7019, -0.7238, -0.9871,  0.8920],\n",
      "        [ 0.7186,  0.3509, -1.2449, -0.6050, -1.2374],\n",
      "        [-1.5025, -1.7547,  1.3607,  0.3503,  1.0647],\n",
      "        [ 1.3718,  1.4037,  0.4922,  0.6687,  0.1439],\n",
      "        [ 0.5879,  0.5615,  1.0133,  1.6876,  0.6043],\n",
      "        [-0.1960,  0.1404, -0.8975, -1.1144, -1.4676]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "sc=StandardScaler()\n",
    "sc.fit_transform(X)\n",
    "#converst the tensor to nparry\n",
    "X_std= torch.tensor(sc.fit_transform(X),dtype=torch.float64)\n",
    "print(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1754378679286,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "T1IRivxn_kW2",
    "outputId": "ca7f671a-9219-4848-954e-097acacc8b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6171, -0.6427, -0.4438],\n",
      "        [ 3.5357, -0.7126,  1.8614],\n",
      "        [-4.7127, -0.1660, -2.3940],\n",
      "        [ 0.2821,  1.4427,  0.3789],\n",
      "        [-1.6298,  1.3386, -1.6126],\n",
      "        [ 3.1418, -1.2601,  2.2101]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#raw score\n",
    "r=torch.matmul(X_std,W)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1754378877337,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "qYMzPvioHgVn",
    "outputId": "8510fb06-7509-4542-87cd-6721db76c771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3161, 0.3081, 0.3759],\n",
      "        [0.8321, 0.0119, 0.1560],\n",
      "        [0.0095, 0.8942, 0.0963],\n",
      "        [0.1889, 0.6030, 0.2081],\n",
      "        [0.0466, 0.9061, 0.0474],\n",
      "        [0.7112, 0.0087, 0.2801]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "sm=torch.nn.Softmax(dim=1)\n",
    "A=sm(r)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1754379293610,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "bJVKlzPwIRs3",
    "outputId": "07721c4a-be1c-4050-80a4-979ddef3e4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.3081, 0.0000],\n",
      "        [0.8321, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8942, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2081],\n",
      "        [0.0466, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2801]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(Y*A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1754379726376,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "CBTenFHcJ5II",
    "outputId": "6007ffc7-fdb1-433a-cd2d-8fb19b15f1aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3081, 0.8321, 0.8942, 0.2081, 0.0466, 0.2801], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "s=torch.sum(Y*A, dim=1)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1754379754042,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "lpd5JsAhKPvX",
    "outputId": "1bcfd8e9-c50b-446a-9799-afbf0bb2f7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1774, 0.1838, 0.1118, 1.5697, 3.0671, 1.2726], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "Loss=-torch.log(s)\n",
    "print(Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1754379819054,
     "user": {
      "displayName": "Abhilash MK",
      "userId": "11688110448264119274"
     },
     "user_tz": -330
    },
    "id": "z_64b74LKrsI",
    "outputId": "b1d680e2-99c8-4df0-b396-32562b9cbb21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2304, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "avg=torch.mean(Loss)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BL7p0G86LzV4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1w_LNEDnf7CduWAXwqNuEsOlpxLRaQgPX",
     "timestamp": 1754372246471
    }
   ]
  },
  "kernelspec": {
   "display_name": "colab-windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
